{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equation Discovery with Symbolic Regression to Paramterize Heat Flux in the Atmospheric Boundary Layer\n",
    "\n",
    "*Authors: Antony Sikorski*\n",
    "\n",
    "This notebook should make it easy to perform equation discovery with the use of the function `discover_eqs`. \n",
    "\n",
    "This function uses a number of supporting functions from the accompanying `functions.py` file, and should output a dataframe of possible equations.\n",
    "\n",
    "We use the `PySR` package for symbolic regression, an ML method for finding interpretable symbolic expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "# from pdfs import *\n",
    "import os\n",
    "import re\n",
    "\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import h5netcdf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "import pysr\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick data processing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/anton/Desktop/Career/LEAP_nyc_Summer2024/les_sim_2/'\n",
    "\n",
    "directories, items = list_directories_files(path)\n",
    "print(\"Directories starting with 'Ug':\", directories)\n",
    "print(\"Files starting with 'Ug':\", items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items:\n",
    "    ds_stat = nc.Dataset( os.path.join(path, item), mode='r')\n",
    "    if 'budget' in ds_stat.groups:\n",
    "        print (\"budget is in\", item)\n",
    "    else:\n",
    "        print (\"budget is not in\", item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items[1:]:\n",
    "    print(item)\n",
    "    df = nc.Dataset(path + '/' + item, mode='r')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_z_dim = 384\n",
    "\n",
    "selected_files = []\n",
    "\n",
    "for item in items[1:]:\n",
    "        df = nc.Dataset(os.path.join(path, item), mode='r')\n",
    "        if df.dimensions['z'].size == target_z_dim:\n",
    "            selected_files.append(item)\n",
    "        df.close()\n",
    "\n",
    "\n",
    "print(\"Total number of files: \", len(items))\n",
    "print(\"Number of valid files (same z and zh dims): \", len(selected_files))\n",
    "print(\"Valid files: \", selected_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eqs_Ug16Q001_IV = discover_eqs(path, ['Ug16Q001_IV.nc'], time_avg = 15, indices = np.s_[:, 0:200], difficulty = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eqs_Ug16Q001_IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eqs_Ug2Q010_IV = discover_eqs(path, ['Ug2Q010_IV.nc'], time_avg = 15, indices = np.s_[:, 0:200], difficulty = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eqs_Ug2Q010_IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqs_easy = discover_eqs(path, selected_files, time_avg = 15, indices = np.s_[:, 0:200], difficulty = \"easy\", normalize = True)\n",
    "# eqs_medium = discover_eqs(path, selected_files, time_avg = 15, indices = np.s_[:, 0:200], difficulty = \"medium\")\n",
    "# eqs_mediumhard = discover_eqs(path, selected_files, time_avg = 15, indices = np.s_[:, 0:200], difficulty = \"mediumhard\")\n",
    "# eqs_hard = discover_eqs(path, selected_files, time_avg = 15, indices = np.s_[:, 0:200], difficulty = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqs_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefs = pd.DataFrame(columns = ['File', 'Avg Ustar', 'Avg Tau', 'Ug', 'Q', 'RMSE', 'R2', 'C1', 'C2', 'C3'])\n",
    "\n",
    "for item in selected_files:\n",
    "    #file\n",
    "    # print(item)\n",
    "    ds_stat = nc.Dataset(os.path.join(path, item), mode='r')\n",
    "\n",
    "    #ustar\n",
    "    ustar = ds_stat.groups['default'].variables['ustar'][:]\n",
    "    # print(\"Mean of ustar: \", np.mean(ustar))\n",
    "\n",
    "    #tau\n",
    "    grr = 9.8\n",
    "    T_0 = 300\n",
    "    beta = grr/T_0\n",
    "    pbl_height = ds_stat.groups['thermo'].variables['zi'][:]\n",
    "    wtheta_surface = ds_stat.groups['thermo']['th_flux'][:,0]  \n",
    "    wstar = np.power( beta * (wtheta_surface) * pbl_height , 1/3) \n",
    "    tau = pbl_height/wstar\n",
    "    # print(\"Mean of tau: \", np.mean(tau))\n",
    "\n",
    "    #ug and q\n",
    "    ug, q = extract_ug_q(item)\n",
    "    # print(\"Ug: \", ug)\n",
    "    # print(\"Q: \", q)\n",
    "\n",
    "    #rmse, r2\n",
    "    fitted_model, X_train, X_test, y_train, y_test, rmse, r2, coefficients = LES_linear_regressor(path, [item], \n",
    "                                                                                                  time_avg = 15, \n",
    "                                                                                                  indices = np.s_[:, 0:200], \n",
    "                                                                                                  verbose = False)\n",
    "    \n",
    "    #c1, c2, c3\n",
    "    c1 = coefficients[0]\n",
    "    c2 = coefficients[1]\n",
    "    c3 = coefficients[2]\n",
    "\n",
    "    # Create a new row to be appended\n",
    "    new_row = {\n",
    "        'File': item,\n",
    "        'Avg Ustar': np.mean(ustar),\n",
    "        'Avg Tau': np.mean(tau),\n",
    "        'Ug': ug,\n",
    "        'Q': q,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'C1': c1,\n",
    "        'C2': c2,\n",
    "        'C3': c3\n",
    "    }\n",
    "\n",
    "    # Append the new row to the DataFrame\n",
    "    df_coefs = pd.concat([df_coefs, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    # print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefs['Inversion Strength'] = [4, 4, 4, 4, 2, 4, 3, 2, 3, 4, 4]\n",
    "df_coefs['C1'] = df_coefs['C1']* df_coefs['Avg Tau']\n",
    "df_coefs['C2'] = df_coefs['C2']/beta\n",
    "df_coefs['C1'] = np.abs(df_coefs['C1'])\n",
    "df_coefs['C2'] = np.abs(df_coefs['C2'])\n",
    "df_coefs['C3'] = np.abs(df_coefs['C3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables and their respective labels and colors\n",
    "variables = ['Q', 'Ug', 'Avg Tau', 'Avg Ustar', 'Inversion Strength']\n",
    "xlabels = ['Q', 'Ug', 'Avg Tau', 'Avg Ustar', 'SI']\n",
    "titles = [\n",
    "    'C1 (wtheta) Values in Relation to {}', \n",
    "    'C2 (theta2) Values in Relation to {}', \n",
    "    'C3 (multiply) Values in Relation to {}'\n",
    "]\n",
    "colors = ['red', 'green', 'blue']\n",
    "columns = ['C1', 'C2', 'C3']\n",
    "\n",
    "# Loop through each variable to create scatter plots\n",
    "for var, xlabel in zip(variables, xlabels):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    for i, (col, color, title) in enumerate(zip(columns, colors, titles)):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.scatter(df_coefs[var], df_coefs[col], label=col, marker='o', color=color)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(f'{col} Values')\n",
    "        plt.title(title.format(xlabel))\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Special case for box plots for 'Inversion Strength'\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    df_coefs.boxplot(column=col, by='Inversion Strength', grid=False, ax=plt.gca(), patch_artist=True)\n",
    "    plt.xlabel('SI')\n",
    "    plt.ylabel(f'{col} Values')\n",
    "    plt.title(f'{col} (wtheta) Values in Relation to SI')\n",
    "    plt.suptitle('')  # Suppress the automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Is there any relationship between fit and the forcings??? ################\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# Plot R2 vs. Q\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.scatter(df_coefs['Q'], df_coefs['R2'], label='R2', marker='o', color='red')\n",
    "plt.xlabel('Q')\n",
    "plt.ylabel('R2 Values')\n",
    "plt.title('R2 Values in Relation to Q')\n",
    "plt.legend()\n",
    "\n",
    "# Plot R2 vs. Ug\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.scatter(df_coefs['Ug'], df_coefs['R2'], label='R2', marker='o', color='green')\n",
    "plt.xlabel('Ug')\n",
    "plt.ylabel('R2 Values')\n",
    "plt.title('R2 Values in Relation to Ug')\n",
    "plt.legend()\n",
    "\n",
    "# Plot R2 vs. Avg Tau\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.scatter(df_coefs['Avg Tau'], df_coefs['R2'], label='R2', marker='o', color='blue')\n",
    "plt.xlabel('Avg Tau')\n",
    "plt.ylabel('R2 Values')\n",
    "plt.title('R2 Values in Relation to Avg Tau')\n",
    "plt.legend()\n",
    "\n",
    "# Plot R2 vs. Avg Ustar\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.scatter(df_coefs['Avg Ustar'], df_coefs['R2'], label='R2', marker='o', color='darkmagenta')\n",
    "plt.xlabel('Avg Ustar')\n",
    "plt.ylabel('R2 Values')\n",
    "plt.title('R2 Values in Relation to Avg Ustar')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Is there any relationship between fit and the forcings??? ################\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# Plot RMSE vs. Q\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.scatter(df_coefs['Q'], df_coefs['RMSE'], label='RMSE', marker='o', color='red')\n",
    "plt.xlabel('Q')\n",
    "plt.ylabel('RMSE Values')\n",
    "plt.title('RMSE Values in Relation to Q')\n",
    "plt.legend()\n",
    "\n",
    "# Plot RMSE vs. Ug\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.scatter(df_coefs['Ug'], df_coefs['RMSE'], label='RMSE', marker='o', color='green')\n",
    "plt.xlabel('Ug')\n",
    "plt.ylabel('RMSE Values')\n",
    "plt.title('RMSE Values in Relation to Ug')\n",
    "plt.legend()\n",
    "\n",
    "# Plot RMSE vs. Avg Tau\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.scatter(df_coefs['Avg Tau'], df_coefs['RMSE'], label='RMSE', marker='o', color='blue')\n",
    "plt.xlabel('Avg Tau')\n",
    "plt.ylabel('RMSE Values')\n",
    "plt.title('RMSE Values in Relation to Avg Tau')\n",
    "plt.legend()\n",
    "\n",
    "# Plot RMSE vs. Avg Ustar\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.scatter(df_coefs['Avg Ustar'], df_coefs['RMSE'], label='RMSE', marker='o', color='purple')\n",
    "plt.xlabel('Avg Ustar')\n",
    "plt.ylabel('RMSE Values')\n",
    "plt.title('RMSE Values in Relation to Avg Ustar')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variable pairs and their respective labels\n",
    "variable_pairs = [\n",
    "    ('Ug', 'Q'), \n",
    "    ('Ug', 'Avg Tau'), \n",
    "    ('Ug', 'Avg Ustar'), \n",
    "    ('Q', 'Avg Tau'), \n",
    "    ('Q', 'Avg Ustar'), \n",
    "    ('Avg Tau', 'Avg Ustar')\n",
    "]\n",
    "\n",
    "xlabel_pairs = [\n",
    "    ('Q', 'Ug'), \n",
    "    ('Avg Tau', 'Ug'), \n",
    "    ('Avg Ustar', 'Ug'), \n",
    "    ('Avg Tau', 'Q'), \n",
    "    ('Avg Ustar', 'Q'), \n",
    "    ('Avg Ustar', 'Avg Tau')\n",
    "]\n",
    "\n",
    "# Function to create heatmap\n",
    "def create_heatmap(ax, x_grid, y_grid, C, xlabel, ylabel, title):\n",
    "    heatmap = ax.pcolormesh(x_grid, y_grid, C, shading='auto', cmap='viridis')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    plt.colorbar(heatmap, ax=ax)\n",
    "\n",
    "# Loop through each variable pair to create the plots\n",
    "for (var1, var2), (xlabel, ylabel) in zip(variable_pairs, xlabel_pairs):\n",
    "    # Pivot tables to create 2D arrays\n",
    "    C1_grid = df_coefs.pivot_table(index=var1, columns=var2, values='C1')\n",
    "    C2_grid = df_coefs.pivot_table(index=var1, columns=var2, values='C2')\n",
    "    C3_grid = df_coefs.pivot_table(index=var1, columns=var2, values='C3')\n",
    "\n",
    "    # Create a meshgrid for var1 and var2\n",
    "    x_values = C1_grid.columns\n",
    "    y_values = C1_grid.index\n",
    "    x_grid, y_grid = np.meshgrid(x_values, y_values)\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    create_heatmap(axes[0], x_grid, y_grid, C1_grid.values, xlabel, ylabel, f'Heatmap of C1 ({xlabel} vs {ylabel})')\n",
    "    create_heatmap(axes[1], x_grid, y_grid, C2_grid.values, xlabel, ylabel, f'Heatmap of C2 ({xlabel} vs {ylabel})')\n",
    "    create_heatmap(axes[2], x_grid, y_grid, C3_grid.values, xlabel, ylabel, f'Heatmap of C3 ({xlabel} vs {ylabel})')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of C2 and C3\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(df_coefs['C2'], df_coefs['C3'], marker='o', color='darkcyan', label='C2 vs C3')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('C2 Values')\n",
    "plt.ylabel('C3 Values')\n",
    "plt.title('Scatter Plot of C2 vs C3')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_l = df_coefs[['Avg Ustar', 'Avg Tau', 'Ug', 'Q']]\n",
    "\n",
    "#normalize the columns of df_X_l using the min max normalization\n",
    "df_X_l = (df_X_l - df_X_l.min()) / (df_X_l.max() - df_X_l.min())\n",
    "\n",
    "df_X_l = df_X_l.rename(columns={'Avg Ustar': 'Ustar', 'Avg Tau': 'Tau', 'Q': 'Q_ic'})\n",
    "df_C1 = df_coefs['C1']\n",
    "df_C2 = df_coefs['C2']\n",
    "df_C3 = df_coefs['C3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c1_eqs = discover_coef_eqs(df_X_l, df_C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c1_eqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c2_eqs = discover_coef_eqs(df_X_l, df_C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c2_eqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c3_eqs = discover_coef_eqs(df_X_l, df_C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c3_eqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- normalize the data, then do symbolic regression. see how well that works. \n",
    "- try both min max and z score normalization\n",
    "\n",
    "- (maybe create jittered/noisy variables for better fit, look up how much paper needs)\n",
    "\n",
    "other things to think abt: \n",
    "- ustar in front of third term (punished coefficient complexity) (think abt)\n",
    "- parametrization for dwwtheta/dz\n",
    "\n",
    "final presi will be: \n",
    "1. the problem (background on turbulence, atmospheric boundary layer, etc)\n",
    "2. the methodology (PYSR, how does it work, genetic algorithms, etc)\n",
    "3. Re-disovery of the original equation.\n",
    "4. Current work on improving the parametrization.\n",
    "\n",
    "Sara will decide how she wants us to present: Hopefully either all three, or Laura and Greta together and then me separate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
